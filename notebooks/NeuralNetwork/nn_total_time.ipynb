{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b26f85-2567-43c9-9343-4d97d61596bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 14:57:40.737118: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-14 14:57:40.745330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749905860.754786  178496 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749905860.757762  178496 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749905860.765110  178496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749905860.765118  178496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749905860.765120  178496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749905860.765120  178496 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-14 14:57:40.767855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Participant  Image  Scene experience  ROI  TotalViewTime\n",
      "0             2.0      1      1    Control    0        32907.0\n",
      "1             2.0      1      1    Control    2         4113.0\n",
      "2             2.0      1      1    Control    3           95.0\n",
      "3             2.0      1      1    Control    4          407.0\n",
      "4             2.0      1      1    Control    5         5517.0\n",
      "...           ...    ...    ...        ...  ...            ...\n",
      "3805       9008.0      2      3    Control   14          771.0\n",
      "3806       9008.0      2      3    Control   15         2013.0\n",
      "3807       9008.0      2      3    Control   16          806.0\n",
      "3808       9008.0      2      3    Control   18          416.0\n",
      "3809       9008.0      2      3    Control   19         1163.0\n",
      "\n",
      "[3810 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries (none here)\n",
    "\n",
    "# Third-party libraries - Core data/science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# scikit-learn - model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scikit-learn - preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# scikit-learn - metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# scikit-learn - ensemble methods\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# scikit-learn - pipeline and feature selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# --- Load the dataset ---\n",
    "df = pd.read_csv(\"../../data/csv/cleaned_fix.csv\")  # Replace with your actual path\n",
    "\n",
    "# --- Sanity check: confirm required columns exist ---\n",
    "required_cols = {'Participant', 'Image', 'Scene', 'FixDur', 'ROI', 'experience'}\n",
    "if not required_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"Missing required columns: {required_cols - set(df.columns)}\")\n",
    "\n",
    "# --- Group by Participant and Image, then sum FixDur to get total viewing time ---\n",
    "viewing_times = df.groupby(['Participant', 'Image', 'Scene', 'experience', 'ROI'])['FixDur'].sum().reset_index()\n",
    "\n",
    "# --- Optional: rename column for clarity ---\n",
    "viewing_times.rename(columns={'FixDur': 'TotalViewTime'}, inplace=True)\n",
    "\n",
    "# --- Display result ---\n",
    "print(viewing_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04abfa4-30b3-4f26-908d-a4f1c36b20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = viewing_times.groupby(['Participant', 'Image', 'Scene', 'experience']).agg(\n",
    "    total_view_time=('TotalViewTime', 'sum'),\n",
    "    mean_roi_view_time=('TotalViewTime', 'mean'),\n",
    "    max_roi_view_time=('TotalViewTime', 'max'),\n",
    "    std_roi_view_time=('TotalViewTime', 'std'),\n",
    "    num_rois_viewed=('ROI', 'count')\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "# Step 2: Feature and label selection\n",
    "X = agg_df[['total_view_time', 'mean_roi_view_time', 'max_roi_view_time',\n",
    "            'std_roi_view_time', 'num_rois_viewed', 'Image', 'Scene']]\n",
    "y = agg_df['experience']\n",
    "\n",
    "# Step 3: Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Step 4: Separate numerical and categorical features\n",
    "numerical_cols = ['total_view_time', 'mean_roi_view_time', 'max_roi_view_time',\n",
    "                  'std_roi_view_time', 'num_rois_viewed']\n",
    "categorical_cols = ['Image', 'Scene']\n",
    "\n",
    "# Step 5: One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_cat = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Step 6: Scale numeric features\n",
    "X_num = StandardScaler().fit_transform(X[numerical_cols])\n",
    "\n",
    "# Step 7: Combine features\n",
    "X_processed = np.hstack([X_num, X_cat])\n",
    "\n",
    "# Step 8: Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976423c0-0fd9-4ae1-935e-e3639d039aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Aggregate the data\n",
    "agg_df = viewing_times.groupby(['Participant', 'Image', 'Scene', 'experience']).agg(\n",
    "    total_view_time=('TotalViewTime', 'sum'),\n",
    "    mean_roi_view_time=('TotalViewTime', 'mean'),\n",
    "    max_roi_view_time=('TotalViewTime', 'max'),\n",
    "    std_roi_view_time=('TotalViewTime', 'std'),\n",
    "    num_rois_viewed=('ROI', 'count')\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "# Step 2: Create ratio and interaction features\n",
    "agg_df['max_mean_ratio'] = agg_df['max_roi_view_time'] / (agg_df['mean_roi_view_time'] + 1e-6)\n",
    "agg_df['std_mean_ratio'] = agg_df['std_roi_view_time'] / (agg_df['mean_roi_view_time'] + 1e-6)\n",
    "agg_df['avg_view_time_per_roi'] = agg_df['total_view_time'] / (agg_df['num_rois_viewed'] + 1e-6)\n",
    "\n",
    "# Step 3: Aggregate average view time per Image and Scene and merge back\n",
    "image_avg = agg_df.groupby('Image')['total_view_time'].mean().rename('image_avg_view_time')\n",
    "scene_avg = agg_df.groupby('Scene')['total_view_time'].mean().rename('scene_avg_view_time')\n",
    "\n",
    "agg_df = agg_df.merge(image_avg, on='Image', how='left')\n",
    "agg_df = agg_df.merge(scene_avg, on='Scene', how='left')\n",
    "\n",
    "# Step 4: Frequency encode Image and Scene categories\n",
    "image_freq = agg_df['Image'].value_counts(normalize=True).rename('image_freq_enc')\n",
    "scene_freq = agg_df['Scene'].value_counts(normalize=True).rename('scene_freq_enc')\n",
    "\n",
    "agg_df = agg_df.join(image_freq, on='Image')\n",
    "agg_df = agg_df.join(scene_freq, on='Scene')\n",
    "\n",
    "# Step 5: Log transform skewed numeric features\n",
    "for col in ['total_view_time', 'mean_roi_view_time', 'max_roi_view_time', 'std_roi_view_time', 'avg_view_time_per_roi']:\n",
    "    agg_df[f'log_{col}'] = np.log1p(agg_df[col])\n",
    "\n",
    "# Step 6: Define feature columns\n",
    "feature_cols = [\n",
    "    'total_view_time', 'mean_roi_view_time', 'max_roi_view_time', 'std_roi_view_time', 'num_rois_viewed',\n",
    "    'max_mean_ratio', 'std_mean_ratio', 'avg_view_time_per_roi',\n",
    "    'image_avg_view_time', 'scene_avg_view_time',\n",
    "    'image_freq_enc', 'scene_freq_enc',\n",
    "    'log_total_view_time', 'log_mean_roi_view_time', 'log_max_roi_view_time', 'log_std_roi_view_time', 'log_avg_view_time_per_roi'\n",
    "]\n",
    "\n",
    "X = agg_df[feature_cols]\n",
    "y = agg_df['experience']\n",
    "\n",
    "# Step 7: Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Step 8: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 9: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3517bd-b8b5-4b74-8633-63a5e7806cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/tf310/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1749905862.508815  178496 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    layers.Dense(36, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c489b5-1300-4bad-815c-e4c6dae522c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439ea6f7-4087-4d5e-81fe-881f464ec408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0091 - loss: 4.4494 - val_accuracy: 0.0000e+00 - val_loss: 3.6952\n",
      "Epoch 2/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0085 - loss: 4.2183 - val_accuracy: 0.0000e+00 - val_loss: 3.6518\n",
      "Epoch 3/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0033 - loss: 4.0088 - val_accuracy: 0.0556 - val_loss: 3.6113\n",
      "Epoch 4/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0052 - loss: 4.0205 - val_accuracy: 0.0556 - val_loss: 3.5729\n",
      "Epoch 5/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0235 - loss: 3.8115 - val_accuracy: 0.1111 - val_loss: 3.5349\n",
      "Epoch 6/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0267 - loss: 3.7045 - val_accuracy: 0.1667 - val_loss: 3.4960\n",
      "Epoch 7/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0548 - loss: 3.6136 - val_accuracy: 0.2222 - val_loss: 3.4558\n",
      "Epoch 8/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0783 - loss: 3.4486 - val_accuracy: 0.2222 - val_loss: 3.4162\n",
      "Epoch 9/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1298 - loss: 3.2849 - val_accuracy: 0.2222 - val_loss: 3.3765\n",
      "Epoch 10/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1083 - loss: 3.2228 - val_accuracy: 0.2778 - val_loss: 3.3372\n",
      "Epoch 11/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2251 - loss: 3.0679 - val_accuracy: 0.3333 - val_loss: 3.2975\n",
      "Epoch 12/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1774 - loss: 3.0775 - val_accuracy: 0.2778 - val_loss: 3.2595\n",
      "Epoch 13/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2231 - loss: 2.9304 - val_accuracy: 0.2778 - val_loss: 3.2202\n",
      "Epoch 14/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1879 - loss: 2.8500 - val_accuracy: 0.2778 - val_loss: 3.1817\n",
      "Epoch 15/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2349 - loss: 2.7589 - val_accuracy: 0.2778 - val_loss: 3.1427\n",
      "Epoch 16/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2270 - loss: 2.6857 - val_accuracy: 0.2778 - val_loss: 3.1027\n",
      "Epoch 17/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2688 - loss: 2.5479 - val_accuracy: 0.2778 - val_loss: 3.0614\n",
      "Epoch 18/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3144 - loss: 2.5536 - val_accuracy: 0.2778 - val_loss: 3.0214\n",
      "Epoch 19/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3509 - loss: 2.3877 - val_accuracy: 0.2222 - val_loss: 2.9789\n",
      "Epoch 20/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3595 - loss: 2.3287 - val_accuracy: 0.2222 - val_loss: 2.9339\n",
      "Epoch 21/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3353 - loss: 2.2556 - val_accuracy: 0.2222 - val_loss: 2.8884\n",
      "Epoch 22/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3861 - loss: 2.2043 - val_accuracy: 0.2222 - val_loss: 2.8409\n",
      "Epoch 23/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3346 - loss: 2.1826 - val_accuracy: 0.2222 - val_loss: 2.7944\n",
      "Epoch 24/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3386 - loss: 2.0499 - val_accuracy: 0.2222 - val_loss: 2.7480\n",
      "Epoch 25/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4259 - loss: 1.9601 - val_accuracy: 0.2222 - val_loss: 2.6978\n",
      "Epoch 26/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3699 - loss: 1.9397 - val_accuracy: 0.2778 - val_loss: 2.6480\n",
      "Epoch 27/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3738 - loss: 1.9754 - val_accuracy: 0.2778 - val_loss: 2.5968\n",
      "Epoch 28/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3686 - loss: 1.8518 - val_accuracy: 0.2778 - val_loss: 2.5453\n",
      "Epoch 29/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2845 - loss: 1.8768 - val_accuracy: 0.2778 - val_loss: 2.4956\n",
      "Epoch 30/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2936 - loss: 1.8675 - val_accuracy: 0.2778 - val_loss: 2.4444\n",
      "Epoch 31/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3373 - loss: 1.7617 - val_accuracy: 0.2222 - val_loss: 2.3922\n",
      "Epoch 32/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3151 - loss: 1.8411 - val_accuracy: 0.2222 - val_loss: 2.3416\n",
      "Epoch 33/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3399 - loss: 1.7663 - val_accuracy: 0.2222 - val_loss: 2.2925\n",
      "Epoch 34/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3757 - loss: 1.6642 - val_accuracy: 0.2222 - val_loss: 2.2483\n",
      "Epoch 35/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3653 - loss: 1.6796 - val_accuracy: 0.2222 - val_loss: 2.2003\n",
      "Epoch 36/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3399 - loss: 1.6450 - val_accuracy: 0.2222 - val_loss: 2.1533\n",
      "Epoch 37/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4168 - loss: 1.4869 - val_accuracy: 0.2222 - val_loss: 2.1066\n",
      "Epoch 38/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3294 - loss: 1.6183 - val_accuracy: 0.2222 - val_loss: 2.0616\n",
      "Epoch 39/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3392 - loss: 1.5898 - val_accuracy: 0.2222 - val_loss: 2.0202\n",
      "Epoch 40/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3816 - loss: 1.5438 - val_accuracy: 0.2222 - val_loss: 1.9829\n",
      "Epoch 41/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4357 - loss: 1.4343 - val_accuracy: 0.2222 - val_loss: 1.9457\n",
      "Epoch 42/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3027 - loss: 1.5277 - val_accuracy: 0.2778 - val_loss: 1.9107\n",
      "Epoch 43/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4012 - loss: 1.5379 - val_accuracy: 0.3333 - val_loss: 1.8760\n",
      "Epoch 44/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3203 - loss: 1.4973 - val_accuracy: 0.3333 - val_loss: 1.8445\n",
      "Epoch 45/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4175 - loss: 1.4533 - val_accuracy: 0.3333 - val_loss: 1.8136\n",
      "Epoch 46/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3491 - loss: 1.4404 - val_accuracy: 0.2778 - val_loss: 1.7883\n",
      "Epoch 47/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3829 - loss: 1.4453 - val_accuracy: 0.2778 - val_loss: 1.7660\n",
      "Epoch 48/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3725 - loss: 1.4342 - val_accuracy: 0.2778 - val_loss: 1.7438\n",
      "Epoch 49/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3992 - loss: 1.4376 - val_accuracy: 0.2778 - val_loss: 1.7259\n",
      "Epoch 50/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3875 - loss: 1.4366 - val_accuracy: 0.2778 - val_loss: 1.7096\n",
      "Epoch 51/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4331 - loss: 1.3341 - val_accuracy: 0.2778 - val_loss: 1.6950\n",
      "Epoch 52/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4579 - loss: 1.4436 - val_accuracy: 0.2778 - val_loss: 1.6793\n",
      "Epoch 53/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4031 - loss: 1.3814 - val_accuracy: 0.2778 - val_loss: 1.6628\n",
      "Epoch 54/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4083 - loss: 1.3315 - val_accuracy: 0.2778 - val_loss: 1.6476\n",
      "Epoch 55/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4247 - loss: 1.3081 - val_accuracy: 0.2222 - val_loss: 1.6344\n",
      "Epoch 56/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4149 - loss: 1.3174 - val_accuracy: 0.2222 - val_loss: 1.6231\n",
      "Epoch 57/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4664 - loss: 1.3267 - val_accuracy: 0.2222 - val_loss: 1.6119\n",
      "Epoch 58/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3627 - loss: 1.3713 - val_accuracy: 0.2222 - val_loss: 1.6014\n",
      "Epoch 59/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4769 - loss: 1.2693 - val_accuracy: 0.2222 - val_loss: 1.5907\n",
      "Epoch 60/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3927 - loss: 1.4098 - val_accuracy: 0.2222 - val_loss: 1.5815\n",
      "Epoch 61/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4025 - loss: 1.3383 - val_accuracy: 0.2222 - val_loss: 1.5720\n",
      "Epoch 62/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4345 - loss: 1.3088 - val_accuracy: 0.2222 - val_loss: 1.5618\n",
      "Epoch 63/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3490 - loss: 1.4176 - val_accuracy: 0.2222 - val_loss: 1.5527\n",
      "Epoch 64/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3973 - loss: 1.2940 - val_accuracy: 0.2222 - val_loss: 1.5423\n",
      "Epoch 65/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4057 - loss: 1.3121 - val_accuracy: 0.2222 - val_loss: 1.5284\n",
      "Epoch 66/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4859 - loss: 1.2428 - val_accuracy: 0.2222 - val_loss: 1.5165\n",
      "Epoch 67/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4110 - loss: 1.2690 - val_accuracy: 0.2222 - val_loss: 1.5064\n",
      "Epoch 68/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4123 - loss: 1.3084 - val_accuracy: 0.1667 - val_loss: 1.5017\n",
      "Epoch 69/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4762 - loss: 1.2090 - val_accuracy: 0.1667 - val_loss: 1.5036\n",
      "Epoch 70/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4820 - loss: 1.2693 - val_accuracy: 0.1667 - val_loss: 1.5076\n",
      "Epoch 71/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3757 - loss: 1.3232 - val_accuracy: 0.1667 - val_loss: 1.5105\n",
      "Epoch 72/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4273 - loss: 1.2831 - val_accuracy: 0.1667 - val_loss: 1.5153\n",
      "Epoch 73/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4488 - loss: 1.2923 - val_accuracy: 0.1667 - val_loss: 1.5185\n",
      "Epoch 74/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4880 - loss: 1.2551 - val_accuracy: 0.1667 - val_loss: 1.5166\n",
      "Epoch 75/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4293 - loss: 1.2374 - val_accuracy: 0.1667 - val_loss: 1.5108\n",
      "Epoch 76/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4625 - loss: 1.2740 - val_accuracy: 0.1667 - val_loss: 1.5048\n",
      "Epoch 77/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4253 - loss: 1.2694 - val_accuracy: 0.1667 - val_loss: 1.4986\n",
      "Epoch 78/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4481 - loss: 1.2868 - val_accuracy: 0.1667 - val_loss: 1.4974\n",
      "Epoch 79/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4214 - loss: 1.2861 - val_accuracy: 0.1667 - val_loss: 1.4959\n",
      "Epoch 80/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4605 - loss: 1.2017 - val_accuracy: 0.1667 - val_loss: 1.4942\n",
      "Epoch 81/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4775 - loss: 1.2517 - val_accuracy: 0.2222 - val_loss: 1.4893\n",
      "Epoch 82/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4259 - loss: 1.2435 - val_accuracy: 0.2778 - val_loss: 1.4831\n",
      "Epoch 83/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4879 - loss: 1.2514 - val_accuracy: 0.2778 - val_loss: 1.4778\n",
      "Epoch 84/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4495 - loss: 1.2278 - val_accuracy: 0.2778 - val_loss: 1.4801\n",
      "Epoch 85/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4338 - loss: 1.2086 - val_accuracy: 0.2778 - val_loss: 1.4873\n",
      "Epoch 86/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4422 - loss: 1.2141 - val_accuracy: 0.2222 - val_loss: 1.4957\n",
      "Epoch 87/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4482 - loss: 1.2362 - val_accuracy: 0.2222 - val_loss: 1.5014\n",
      "Epoch 88/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5173 - loss: 1.1747 - val_accuracy: 0.1667 - val_loss: 1.5088\n",
      "Epoch 89/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4240 - loss: 1.2783 - val_accuracy: 0.1667 - val_loss: 1.5149\n",
      "Epoch 90/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5036 - loss: 1.1949 - val_accuracy: 0.1667 - val_loss: 1.5149\n",
      "Epoch 91/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4586 - loss: 1.2145 - val_accuracy: 0.1667 - val_loss: 1.5186\n",
      "Epoch 92/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4175 - loss: 1.2943 - val_accuracy: 0.1667 - val_loss: 1.5211\n",
      "Epoch 93/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4592 - loss: 1.2069 - val_accuracy: 0.2222 - val_loss: 1.5268\n",
      "Epoch 94/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4338 - loss: 1.1962 - val_accuracy: 0.2222 - val_loss: 1.5289\n",
      "Epoch 95/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4475 - loss: 1.1748 - val_accuracy: 0.2222 - val_loss: 1.5275\n",
      "Epoch 96/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4749 - loss: 1.1611 - val_accuracy: 0.2222 - val_loss: 1.5258\n",
      "Epoch 97/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5642 - loss: 1.1561 - val_accuracy: 0.2222 - val_loss: 1.5200\n",
      "Epoch 98/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5277 - loss: 1.1615 - val_accuracy: 0.2222 - val_loss: 1.5097\n",
      "Epoch 99/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4599 - loss: 1.1548 - val_accuracy: 0.2222 - val_loss: 1.5027\n",
      "Epoch 100/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4788 - loss: 1.1896 - val_accuracy: 0.2222 - val_loss: 1.4978\n",
      "Epoch 101/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4866 - loss: 1.1795 - val_accuracy: 0.2222 - val_loss: 1.4932\n",
      "Epoch 102/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4573 - loss: 1.1948 - val_accuracy: 0.1667 - val_loss: 1.4922\n",
      "Epoch 103/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5147 - loss: 1.1555 - val_accuracy: 0.1667 - val_loss: 1.4966\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=500,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bc155b-2ec4-410b-bbc1-86e112d96f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3161 - loss: 1.4899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.485798954963684, 0.302325576543808]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d9c7fb-b949-4a7a-98d6-7cc42b9044d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.20930232558139536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06564dff-54a0-42d5-9790-b2e1a115c830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2558139534883721\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CSI       0.11      0.09      0.10        11\n",
      "     Control       0.22      0.18      0.20        11\n",
      "   FirstYear       0.33      0.40      0.36        10\n",
      "   ThirdYear       0.31      0.36      0.33        11\n",
      "\n",
      "    accuracy                           0.26        43\n",
      "   macro avg       0.24      0.26      0.25        43\n",
      "weighted avg       0.24      0.26      0.25        43\n",
      "\n",
      "Selected features: ['total_view_time', 'mean_roi_view_time', 'max_roi_view_time', 'std_roi_view_time', 'num_rois_viewed']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Step 1: Aggregate your data ---\n",
    "agg_df = viewing_times.groupby(['Participant', 'Image', 'Scene', 'experience']).agg(\n",
    "    total_view_time=('TotalViewTime', 'sum'),\n",
    "    mean_roi_view_time=('TotalViewTime', 'mean'),\n",
    "    max_roi_view_time=('TotalViewTime', 'max'),\n",
    "    std_roi_view_time=('TotalViewTime', 'std'),\n",
    "    num_rois_viewed=('ROI', 'count')\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "# --- Step 2: Define features and target ---\n",
    "X = agg_df[['total_view_time', 'mean_roi_view_time', 'max_roi_view_time',\n",
    "            'std_roi_view_time', 'num_rois_viewed', 'Image', 'Scene']]\n",
    "y = agg_df['experience']\n",
    "\n",
    "# --- Step 3: Encode target ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# --- Step 4: Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 5: Preprocessing pipelines for numeric and categorical features ---\n",
    "numeric_features = ['total_view_time', 'mean_roi_view_time', 'max_roi_view_time',\n",
    "                    'std_roi_view_time', 'num_rois_viewed']\n",
    "categorical_features = ['Image', 'Scene']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Step 6: Create model (Random Forest) ---\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# --- Step 7: Create pipeline with preprocessor and RFE ---\n",
    "# RFE with Random Forest as the estimator, selecting top 5 features\n",
    "rfe_selector = RFE(estimator=model, n_features_to_select=5, step=1)\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', rfe_selector),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# --- Step 8: Train ---\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- Step 9: Evaluate ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# --- Step 10 (optional): Check which features were selected ---\n",
    "# Get feature names after one-hot encoding\n",
    "ohe_feature_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "all_features = numeric_features + list(ohe_feature_names)\n",
    "selected_mask = pipeline.named_steps['feature_selector'].support_\n",
    "selected_features = [f for f, selected in zip(all_features, selected_mask) if selected]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f3d059-feda-4c12-809b-ed22a417ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.2558139534883721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CSI       0.11      0.09      0.10        11\n",
      "     Control       0.22      0.18      0.20        11\n",
      "   FirstYear       0.33      0.40      0.36        10\n",
      "   ThirdYear       0.31      0.36      0.33        11\n",
      "\n",
      "    accuracy                           0.26        43\n",
      "   macro avg       0.24      0.26      0.25        43\n",
      "weighted avg       0.24      0.26      0.25        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_numeric = agg_df[['total_view_time', 'mean_roi_view_time', 'max_roi_view_time', 'std_roi_view_time', 'num_rois_viewed']]\n",
    "y = agg_df['experience']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b124401d-a872-4bda-976c-379392c6463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4186046511627907\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         CSI       0.43      0.27      0.33        11\n",
      "     Control       0.50      0.55      0.52        11\n",
      "   FirstYear       0.40      0.40      0.40        10\n",
      "   ThirdYear       0.36      0.45      0.40        11\n",
      "\n",
      "    accuracy                           0.42        43\n",
      "   macro avg       0.42      0.42      0.41        43\n",
      "weighted avg       0.42      0.42      0.41        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/tf310/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:57:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Features and target\n",
    "X_numeric = agg_df[['total_view_time', 'mean_roi_view_time', 'max_roi_view_time', \n",
    "                    'std_roi_view_time', 'num_rois_viewed']]\n",
    "y = agg_df['experience']\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numeric, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features (optional, but good practice)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(label_encoder.classes_),\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
